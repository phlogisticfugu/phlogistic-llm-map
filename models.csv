"name","predecessor_name","publish_date","publisher","publish_url","num_citations","is_free_commercial_use"
"Transformer","","2017-06-12","Google","https://arxiv.org/abs/1706.03762",83844,"N"
"GPT","Transformer","2018-06-11","OpenAI","https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf",6152,"N"
"PaLM","Transformer","2022-04-05","Google","https://arxiv.org/abs/2204.02311",1263,"N"
"BERT","Transformer","2018-10-11","Google","https://arxiv.org/abs/1810.04805",74143,"Y"
"DistilBERT","BERT","2019-10-02","Hugging Face","https://arxiv.org/abs/1910.01108",4045,"Y"
"ERNIE","BERT","2019-04-19","Baidu","https://arxiv.org/abs/1904.09223",821,"Y"
"ERNIE 2.0","ERNIE","2020-04-03","Baidu","https://ojs.aaai.org/index.php/AAAI/article/view/6428",633,"Y"
"ERNIE 3.0","ERNIE 2.0","2021-07-05","Baidu","https://arxiv.org/abs/2107.02137",169,"Y"
"ALBERT","BERT","2019-09-01","Google","https://arxiv.org/abs/1909.11942",5288,"Y"
"UniLM","BERT","2019-05-08","Microsoft","https://arxiv.org/abs/1905.03197",1285,"N"
"UniLMv2","UniLM","2020-02-28","Microsoft","https://arxiv.org/abs/2002.12804",299,"N"
"ELECTRA","RoBERTa","2020-03-23","Google","https://arxiv.org/abs/2003.10555",2722,"Y"
"AlexaTM","BERT","2022-08-02","Amazon","https://arxiv.org/abs/2208.01448",31,"N"
"RoBERTa","BERT","2019-07-26","Meta","https://arxiv.org/abs/1907.11692",187,"Y"
"T5","BERT","2019-10-23","Google","https://arxiv.org/abs/1910.10683",9217,"Y"
"Switch Transformer","Transformer","2021-01-11","Google","https://arxiv.org/abs/2101.03961",812,"N"
"ST-MoE","Switch Transformer","2022-02-17","Google","https://arxiv.org/abs/2202.08906",12,"N"
"DeBERTa","RoBERTa","2020-06-05","Microsoft","https://arxiv.org/abs/2006.03654",1172,"Y"
"BART","BERT","2019-10-29","Meta","https://arxiv.org/abs/1910.13461",6118,"Y"
"GPT-2","GPT","2019-02-14","OpenAI","https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf",6346,"N"
"GPT-3","GPT-2","2020-05-28","OpenAI","https://arxiv.org/abs/2005.14165",12900,"N"
"GPT-J","GPT-3","2021-06-09","Eleuther AI","https://gpt3demo.com/apps/gpt-j-6b",0,"Y"
"InstructGPT","GPT-3","2022-03-04","OpenAI","https://arxiv.org/abs/2203.02155",1630,"N"
"Codex","GPT-3","2021-08-10","OpenAI","https://openai.com/blog/openai-codex",0,"N"
"GPT-3.5","GPT-3","2022-03-15","OpenAI","https://openai.com/blog/gpt-3-edit-insert/",0,"N"
"Gopher","GPT-3","2021-12-08","Google","http://arxiv.org/abs/2112.11446v2",414,"N"
"OPT","GPT-3","2022-05-02","Meta","https://arxiv.org/abs/2205.01068",574,"Y"
"GLM","PaLM","2022-10-05","Zhipu AI","https://arxiv.org/abs/2210.02414",40,"N"
"BLOOM","GPT","2022-11-09","BigScience Workshop","https://arxiv.org/abs/2211.05100",338,"Y"
"MT-NLG","GPT-3","2022-01-28","Microsoft","https://arxiv.org/abs/2201.11990",281,"N"
"GLaM","GPT-3","2021-12-13","Google","https://arxiv.org/abs/2112.06905",147,"N"
"Chinchilla","Gopher","2022-03-29","Google","https://arxiv.org/abs/2203.15556",122,"N"
"LaMDA","GPT-3","2022-01-20","Google","https://arxiv.org/abs/2201.08239",498,"N"
"Alpaca","LLaMA","2023-02-27","Stanford","https://crfm.stanford.edu/2023/03/13/alpaca.html",0,"N"
"GPT-4 (ChatGPT)","GPT-3.5","2023-03-15","OpenAI","http://arxiv.org/abs/2303.08774v2",0,"N"
"BloombergGPT","BLOOM","2023-03-30","Bloomberg","https://arxiv.org/abs/2303.17564",55,"N"
"GPT-NeoX","GPT-J","2022-04-14","Eleuther AI","https://arxiv.org/abs/2204.06745",212,"Y"
"Jurassic-1","GPT-3","2021-08-18","AI21","https://assets-global.website-files.com/60fd4503684b466578c0d307/61138924626a6981ee09caf6_jurassic_tech_paper.pdf",108,"Y"
"GPT-Neo","GPT-3","2021-03-01","Eleuther AI","https://github.com/EleutherAI/gpt-neo",0,"N"
"PaLM 2 (Bard)","PaLM","2023-05-17","Google","https://arxiv.org/abs/2305.10403",63,"N"
"Jurassic-2","Jurassic-1","2023-03-09","AI21","https://docs.ai21.com/docs/jurassic-2-models",0,"Y"
"LLaMA 2","LLaMA","2023-07-18","Meta","https://arxiv.org/abs/2307.09288",68,"N"
"Dolly","GPT-J","2023-03-24","Databricks","https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html",10,"Y"
"Pythia","GPT-3","2023-04-03","Eleuther AI","https://arxiv.org/abs/2304.01373",46,"Y"
"Dolly 2.0","Pythia","2023-04-12","Databricks","https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm",0,"Y"
"mT5","T5","2020-10-22","Google","https://arxiv.org/abs/2010.11934",1100,"Y"
"T0","T5","2021-10-15","Various","https://arxiv.org/abs/2110.08207",591,"N"
"CodeGen","GPT-J","2022-03-25","Salesforce","https://arxiv.org/abs/2203.13474",103,"N"
"Tk-Instruct","T5","2022-04-16","Various","https://arxiv.org/abs/2204.07705",75,"N"
"PanGu-Î±","Transformer","2021-04-26","PCNL","https://arxiv.org/abs/2104.12369",127,"N"
"UL2","T5","2022-05-10","Google","https://arxiv.org/abs/2205.05131",26,"Y"
"NLLB","Transformer","2022-07-11","Meta","https://arxiv.org/abs/2207.04672",116,"N"
"Flan-T5","T5","2022-10-20","Google","https://arxiv.org/abs/2210.11416",359,"Y"
"Flan-PaLM","PaLM","2022-10-20","Google","https://arxiv.org/abs/2210.11416",359,"Y"
"BLOOMZ","BLOOM","2022-11-03","Various","https://arxiv.org/abs/2211.01786",65,"Y"
"mT0","mT5","2022-11-03","Various","https://arxiv.org/abs/2211.01786",65,"Y"
"FLAN","GPT-3","2021-09-03","Google","https://arxiv.org/abs/2109.01652",719,"Y"
"Anthropic LM","GPT-3","2021-12-01","Anthropic","https://arxiv.org/abs/2112.00861",39,"N"
"LLaMA","GPT-3","2023-02-27","Meta","https://arxiv.org/abs/2302.13971v1",742,"N"
"Falcon","GPT-3","2023-06-05","TII","https://falconllm.tii.ae/",0,"Y"
"Claude","Anthropic LM","2023-03-14","Anthropic","https://www.anthropic.com/index/introducing-claude",0,"N"
"Claude 2","Claude","2023-07-11","Anthropic","https://www.anthropic.com/index/claude-2",0,"N"
"Vicuna","LLaMA","2023-03-30","LMSYS","https://lmsys.org/blog/2023-03-30-vicuna/",0,"Y"
"StableLM-Alpha","GPT-NeoX","2023-04-20","Stability AI","https://stability.ai/blog/stability-ai-launches-the-first-of-its-stablelm-suite-of-language-models",0,"Y"
"MPT-7B","GPT-3","2023-05-05","MosaicML","https://www.mosaicml.com/blog/mpt-7b",0,"Y"
"MPT-30B","MPT-7B","2023-06-22","MosaicML","https://www.mosaicml.com/blog/mpt-30b",0,"Y"
"XGen","LLaMA","2023-07-02","Salesforce","https://blog.salesforceairesearch.com/xgen/",0,"Y"
"Orca","LLaMA","2023-06-05","Microsoft","https://arxiv.org/abs/2306.02707",8,"Y"
"Code Llama","LLaMA 2","2023-08-24","Meta","https://ai.meta.com/blog/code-llama-large-language-model-coding/",0,"N"
"SeamlessM4T","NLLB","2023-08-22","Meta","https://arxiv.org/abs/2308.11596",0,"N"
